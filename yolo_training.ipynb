{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f02b34",
   "metadata": {},
   "source": [
    "### 1. Dataset creation\n",
    "\n",
    "Since no datasets existed, the idea was to create my own using blender and check if automatically generated dataset could be created from taking pictures of assets in Blender. Therefore multiple 3D object of pokémons have been downloaded and a script called blender_script has been coded to make multiple pictures of those pokémons creating the needed dataset.\n",
    "The command to create picture is `blender --background --python \"blender_script.py\"` (from project root). Multiple datasets have been made (from dataset1 to dataset6) with small modifications to create the one that gives best results.\n",
    "\n",
    "As proof of concept only 9 Pokémon models have been downloaded: Abra, Chansey, Eevee, Jigglypuff, Pidgeotto, Pidgey, Psyduck, Rattata, Vulpix.\n",
    "Those Pokémons corresponds to the entities that can be encountered in route 8 in the game \"Pokémon: Let's go, Eevee\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724834b4",
   "metadata": {},
   "source": [
    "### 2. Data augmentation and COCO to YOLO conversion\n",
    "\n",
    "To ensure there was enough data and to train the model more efficiently, datasets were subjected to data augmentation using albumentations. Three augmented version of each images are attempted but it may happen that no augmentation have been triggered resulting in an omission in this case. Those initially COCO format datasets were during reformatted in YOLO datasets containing an image with a 80/20 split ratio for training and validation\n",
    "sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b81ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import shutil\n",
    "import yaml\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "\n",
    "COCO_ANNOTS = \"datasets/dataset6-annotations.json\"\n",
    "IMAGES_DIR = \"datasets/dataset6-images\"\n",
    "YOLO_OUT = \"datasets/dataset6-neg_bg\"\n",
    "YOLO_OUT_AUG = \"datasets/dataset6-neg_bg_aug\"\n",
    "\n",
    "NUM_AUGS_PER_IMAGE = 3\n",
    "TRAIN_RATIO = 0.8\n",
    "SEED = 511\n",
    "\n",
    "augmentations = [\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(),\n",
    "        A.ISONoise()\n",
    "    ]),\n",
    "    A.CoarseDropout(num_holes_range=(1, 3), fill=(123, 176, 84), p=0.25),\n",
    "    A.RandomBrightnessContrast(),\n",
    "    A.RandomGamma(),\n",
    "    A.HueSaturationValue(),\n",
    "    A.Blur(),\n",
    "    A.MotionBlur(),\n",
    "    A.ToGray(p=0.2),\n",
    "    A.Affine(shear=(-10, 10), p=0.3),\n",
    "    A.Affine(scale=(0.5, 1), p=0.3),\n",
    "    A.ElasticTransform(p=0.2)\n",
    "]\n",
    "\n",
    "transform = A.Compose(\n",
    "    augmentations,\n",
    "    bbox_params=A.BboxParams(format='coco', label_fields=['category_ids'], min_visibility=0.05)\n",
    ")\n",
    "\n",
    "def coco_to_yolo(image_list, split_name, images_input_dir,\n",
    "                images_output_dir, labels_output_dir,\n",
    "                image_annots, category_mapping):\n",
    "\n",
    "    for image_info in tqdm(image_list, desc=f\"Converting {split_name} set\"):\n",
    "        image_id = image_info['id']\n",
    "        image_filename = image_info['file_name']\n",
    "        image_width = image_info['width']\n",
    "        image_height = image_info['height']\n",
    "\n",
    "        if os.path.isdir(images_input_dir):\n",
    "            source_image_path = None\n",
    "            for root, _, files in os.walk(images_input_dir):\n",
    "                if image_filename in files:\n",
    "                    source_image_path = os.path.join(root, image_filename)\n",
    "                    break\n",
    "        else:\n",
    "            source_image_path = images_input_dir if os.path.basename(images_input_dir) == image_filename else None\n",
    "\n",
    "        if not source_image_path or not os.path.exists(source_image_path):\n",
    "            continue\n",
    "\n",
    "        dest_image_path = os.path.join(images_output_dir, image_filename)\n",
    "        shutil.copy2(source_image_path, dest_image_path)\n",
    "\n",
    "        label_filename = os.path.splitext(image_filename)[0] + \".txt\"\n",
    "        label_path = os.path.join(labels_output_dir, label_filename)\n",
    "\n",
    "        yolo_annotations = []\n",
    "        if image_id in image_annots:\n",
    "            for ann in image_annots[image_id]:\n",
    "                coco_bbox = ann['bbox']\n",
    "                x, y, w, h = coco_bbox\n",
    "\n",
    "                # Convert to YOLO format\n",
    "                center_x = (x + w/2) / image_width\n",
    "                center_y = (y + h/2) / image_height\n",
    "                norm_width = w / image_width\n",
    "                norm_height = h / image_height\n",
    "\n",
    "                coco_category_id = ann['category_id']\n",
    "                yolo_class_id = category_mapping[coco_category_id]\n",
    "\n",
    "                yolo_line = f\"{yolo_class_id} {center_x:.6f} {center_y:.6f} {norm_width:.6f} {norm_height:.6f}\"\n",
    "                yolo_annotations.append(yolo_line)\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write('\\n'.join(yolo_annotations))\n",
    "            if yolo_annotations:\n",
    "                f.write('\\n')\n",
    "    return\n",
    "\n",
    "def data_aug_and_split(input_annot_file, input_images_dir, output_yolo_dir, output_yolo_aug_dir):\n",
    "    random.seed(SEED)\n",
    "    with open(input_annot_file, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    categories = coco_data['categories']\n",
    "    category_mapping = {}\n",
    "    class_names = []\n",
    "    sorted_categories = sorted(categories, key=lambda x: x['id'])\n",
    "    for idx, category in enumerate(sorted_categories):\n",
    "        category_mapping[category['id']] = idx\n",
    "        class_names.append(category['name'])\n",
    "\n",
    "    # Split images into train and validation\n",
    "    images_list = list(coco_data['images'])\n",
    "    random.shuffle(images_list)\n",
    "    train_count = int(len(images_list) * TRAIN_RATIO)\n",
    "    train_images = images_list[:train_count]\n",
    "    val_images = images_list[train_count:]\n",
    "\n",
    "    image_id_to_annotations = {}\n",
    "    for annot in coco_data['annotations']:\n",
    "        image_id = annot['image_id']\n",
    "        image_id_to_annotations.setdefault(image_id, []).append(annot)\n",
    "\n",
    "    for yolo_dir in [output_yolo_dir, output_yolo_aug_dir]:\n",
    "        os.makedirs(os.path.join(yolo_dir, \"images\", \"train\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(yolo_dir, \"images\", \"val\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(yolo_dir, \"labels\", \"train\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(yolo_dir, \"labels\", \"val\"), exist_ok=True)\n",
    "\n",
    "    # Process regular dataset\n",
    "    print(f\"Processing images without augmentation...\")\n",
    "    coco_to_yolo(train_images, \"training regular\", input_images_dir, \n",
    "                os.path.join(output_yolo_dir, \"images\", \"train\"),\n",
    "                os.path.join(output_yolo_dir, \"labels\", \"train\"),\n",
    "                image_id_to_annotations, category_mapping)\n",
    "\n",
    "    coco_to_yolo(val_images, \"validation regular\", input_images_dir,\n",
    "                os.path.join(output_yolo_dir, \"images\", \"val\"),\n",
    "                os.path.join(output_yolo_dir, \"labels\", \"val\"),\n",
    "                image_id_to_annotations, category_mapping)\n",
    "\n",
    "    # Create dataset.yaml for regular dataset\n",
    "    yaml_content = {\n",
    "        'path': output_yolo_dir,\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'nc': len(class_names),\n",
    "        'names': class_names\n",
    "    }\n",
    "    with open(os.path.join(output_yolo_dir, 'dataset.yaml'), 'w') as f:\n",
    "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "\n",
    "    # Augment training images\n",
    "    print(f\"Processing images with augmentation...\")\n",
    "    for image in tqdm(train_images, desc=\"Augmenting training images\"):\n",
    "        if os.path.isdir(input_images_dir):\n",
    "            img_path = None\n",
    "            for root, _, files in os.walk(input_images_dir):\n",
    "                if image['file_name'] in files:\n",
    "                    img_path = os.path.join(root, image['file_name'])\n",
    "                    break\n",
    "        else:\n",
    "            img_path = input_images_dir if os.path.basename(input_images_dir) == image['file_name'] else None\n",
    "\n",
    "        image_id = image['id']\n",
    "        annots = image_id_to_annotations.get(image_id, [])\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Couldn't read {img_path}\")\n",
    "            continue\n",
    "\n",
    "        if annots:\n",
    "            bboxes = [ann['bbox'] for ann in annots]\n",
    "            category_ids = [ann['category_id'] for ann in annots]\n",
    "        else:\n",
    "            bboxes = []\n",
    "            category_ids = []\n",
    "\n",
    "        for i in range(NUM_AUGS_PER_IMAGE + 1):\n",
    "            try:\n",
    "                if i == 0:\n",
    "                    aug_img = img.copy()\n",
    "                    aug_bboxes = bboxes\n",
    "                    aug_categories = category_ids\n",
    "                else:\n",
    "                    if bboxes:\n",
    "                        augmented = transform(image=img, bboxes=bboxes, category_ids=category_ids)\n",
    "                        aug_img = augmented['image']\n",
    "                        aug_bboxes = augmented['bboxes']\n",
    "                        aug_categories = augmented['category_ids']\n",
    "                    else:\n",
    "                        bg_transform = A.Compose(augmentations)\n",
    "                        augmented = bg_transform(image=img)\n",
    "                        aug_img = augmented['image']\n",
    "                        aug_bboxes = []\n",
    "                        aug_categories = []\n",
    "\n",
    "                new_filename = f\"{Path(image['file_name']).stem}_aug{i}.png\"\n",
    "                new_img_path = os.path.join(output_yolo_aug_dir, \"images\", \"train\", new_filename)\n",
    "                cv2.imwrite(new_img_path, aug_img)\n",
    "\n",
    "                label_filename = f\"{Path(image['file_name']).stem}_aug{i}.txt\"\n",
    "                label_path = os.path.join(output_yolo_aug_dir, \"labels\", \"train\", label_filename)\n",
    "\n",
    "                yolo_annotations = []\n",
    "                for bbox, cat_id in zip(aug_bboxes, aug_categories):\n",
    "                    x, y, w, h = bbox\n",
    "                    center_x = (x + w/2) / aug_img.shape[1]\n",
    "                    center_y = (y + h/2) / aug_img.shape[0]\n",
    "                    norm_width = w / aug_img.shape[1]\n",
    "                    norm_height = h / aug_img.shape[0]\n",
    "                    yolo_class_id = category_mapping[cat_id]\n",
    "                    yolo_line = f\"{yolo_class_id} {center_x:.6f} {center_y:.6f} {norm_width:.6f} {norm_height:.6f}\"\n",
    "                    yolo_annotations.append(yolo_line)\n",
    "\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write('\\n'.join(yolo_annotations))\n",
    "                    if yolo_annotations:\n",
    "                        f.write('\\n')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error while Augmenting {img_path} aug{i}: {e}\")\n",
    "\n",
    "    print(\"Copying validation images to augmented dataset...\")\n",
    "    coco_to_yolo(val_images, \"validation\", input_images_dir,\n",
    "                os.path.join(output_yolo_aug_dir, \"images\", \"val\"),\n",
    "                os.path.join(output_yolo_aug_dir, \"labels\", \"val\"),\n",
    "                image_id_to_annotations, category_mapping)\n",
    "\n",
    "    # Create dataset.yaml for augmented dataset\n",
    "    yaml_content_aug = {\n",
    "        'path': output_yolo_aug_dir,\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'nc': len(class_names),\n",
    "        'names': class_names\n",
    "    }\n",
    "    with open(os.path.join(output_yolo_aug_dir, 'dataset.yaml'), 'w') as f:\n",
    "        yaml.dump(yaml_content_aug, f, default_flow_style=False)\n",
    "\n",
    "# Process both datasets\n",
    "if os.path.exists(COCO_ANNOTS) and os.path.exists(IMAGES_DIR):\n",
    "    print(\"Processing dataset...\")\n",
    "    data_aug_and_split(COCO_ANNOTS, IMAGES_DIR, YOLO_OUT, YOLO_OUT_AUG)\n",
    "    print(\"Dataset processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4e35f1",
   "metadata": {},
   "source": [
    "### 3. Check for GPU usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7c012",
   "metadata": {},
   "source": [
    "Since training was too low, it has been constated that the cpu was in fact used for training. Those few lines permit to be sure that the GPU is being used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU {torch.cuda.get_device_name(0)} will be used for training.\")\n",
    "else:\n",
    "    print(\"CPU will be used for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80631a13",
   "metadata": {},
   "source": [
    "While training different models one after the other without restarting the computer, the computer had tendency to crash during training. Those small functions should help preventing that by checking RAM usage and by emptying cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2824c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "def check_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Total RAM: {memory.total / (1024**3):.1f} GB\")\n",
    "    print(f\"Available RAM: {memory.available / (1024**3):.1f} GB\")\n",
    "    print(f\"Used RAM: {memory.used / (1024**3):.1f} GB ({memory.percent}%)\")\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "check_memory()\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8096dcd",
   "metadata": {},
   "source": [
    "### 4. Install and train model\n",
    "\n",
    "The model that has been chosen is yolo11n. The best performing model has also been trained on yolo11s and an attempt has been made to use yolo11m but this model was too big for the ressources I have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f245cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "\n",
    "IN_MODELS_DIR = \"downloaded_models\"\n",
    "OUT_MODELS_DIR = \"trained_models\"\n",
    "\n",
    "config = {\n",
    "    \"imgsz\": 640,\n",
    "    \"epochs\": 50,\n",
    "    \"batch\": 16,\n",
    "    \"device\": 0 if torch.cuda.is_available() else 'cpu',\n",
    "    \"save\": True,\n",
    "    \"exist_ok\": True,\n",
    "    \"verbose\": True,\n",
    "    \"workers\": 4,\n",
    "    \"cache\": 'disk',\n",
    "}\n",
    "\n",
    "# Models to download\n",
    "models_name = [\"yolo11n\", \"yolo11s\"]\n",
    "\n",
    "# Download models\n",
    "for model_name in models_name:\n",
    "    model_path = f\"{IN_MODELS_DIR}/{model_name}.pt\"\n",
    "    os.makedirs(f'{IN_MODELS_DIR}', exist_ok=True)\n",
    "    model = YOLO(model_name)\n",
    "    model.save(model_path)\n",
    "    print(f\"Downloaded {model_name} in {IN_MODELS_DIR}/\")\n",
    "    os.remove(f\"{model_name}.pt\")\n",
    "\n",
    "# Define the training function\n",
    "def train_model(model_name, dataset_name, dataset_path):\n",
    "    print(f\"Training {model_name}\")\n",
    "    results = None\n",
    "    try:\n",
    "        model = YOLO(f\"{IN_MODELS_DIR}/{model_name}.pt\")\n",
    "        print(f\"Loaded {model_name}.pt successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {model_name}.pt: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Training on {dataset_name} dataset...\")\n",
    "    print(f\"Dataset: {dataset_path}\")\n",
    "\n",
    "    project_name = OUT_MODELS_DIR\n",
    "    run_name = f\"{model_name}_{dataset_name}\"\n",
    "    results_summary = {}\n",
    "\n",
    "    try:\n",
    "        results = model.train(\n",
    "            data=dataset_path,\n",
    "            project=project_name,\n",
    "            name=run_name,\n",
    "            **config\n",
    "        )\n",
    "\n",
    "        if results:\n",
    "            results_summary = {\n",
    "                \"model\": model_name,\n",
    "                \"dataset\": dataset_name,\n",
    "                \"project\": project_name,\n",
    "                \"results\": results,\n",
    "                \"status\": \"Completed\"\n",
    "            }\n",
    "            print(f\"{model_name} training completed on {dataset_name}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Training completed but no results returned\")\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"Training failed for {model_name} on {dataset_name}\")\n",
    "        print(f\"Error: {error_msg}\")\n",
    "\n",
    "        results_summary = {\n",
    "            \"model\":model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"project\": project_name,\n",
    "            \"results\": None,\n",
    "            \"status\": f\"Failed: {error_msg}\",\n",
    "            \"error\": error_msg\n",
    "        }\n",
    "        return\n",
    "    finally:\n",
    "        summary = results_summary\n",
    "        print(f\"\\n{model_name} using {dataset_name}:\")\n",
    "        print(f\"   Model: {summary['model']}\")\n",
    "        print(f\"   Dataset: {summary['dataset']}\")\n",
    "        print(f\"   Status: {summary['status']}\")\n",
    "        print(f\"   Project: {summary['project']}\")\n",
    "        print(f\"   Status: {summary['status']}\")\n",
    "        print(f\"   Error: {summary.get('error', 'No error')}\")\n",
    "        if hasattr(results, 'results_dict'):\n",
    "            metrics = results.results_dict\n",
    "            print(f\"   Key Metrics:\")\n",
    "            for key, value in metrics.items():\n",
    "                if isinstance(value, (int, float)):\n",
    "                    print(f\"      {key}: {value:.4f}\")\n",
    "\n",
    "        print(\"\\nTraining completed!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314cece0",
   "metadata": {},
   "source": [
    "##### Model training\n",
    "\n",
    "The model yolo11n have been retrained on multiple different datasets, searching for the most suitable one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e677cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_memory()\n",
    "train_model(\"yolo11n\", \"dataset6-neg_bg_aug\", \"datasets/dataset6-neg_bg_aug/dataset.yaml\")\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892ac38",
   "metadata": {},
   "source": [
    "The best performant dataset on yolo11n has been used to retrained the bigger model yolo11s to examine the difference on performance with yolo11n model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_memory()\n",
    "train_model(\"yolo11s\", \"dataset6bis-neg_bg_aug\", \"datasets/dataset6bis-neg_bg_aug/dataset.yaml\")\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068bac3",
   "metadata": {},
   "source": [
    "The resulting model called `dataset6bis-neg_bg_aug` has been reused on 50 manually labeled images from the game \"Pokémon: Let's go, Eevee\" to create a last model called `Pokédetector.pt` powerful enough to detect Pokémon efficiently in the corresponding game. This resulting model can be used to create a database for training an AI model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e038fed",
   "metadata": {},
   "source": [
    "### 5. `Pokédetector` usage for Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c59356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "SRC_DIR = \"final_dataset/original_images\"\n",
    "OUT_PROJECT = \"final_dataset\"\n",
    "OUT_RUN_NAME = \"\"\n",
    "\n",
    "IOU_THRESHOLD = 0.4\n",
    "CONF_THRESHOLD = 0.7\n",
    "\n",
    "os.makedirs(OUT_PROJECT, exist_ok=True)\n",
    "\n",
    "model = YOLO(\"trained_models/last_model/pokedetector.pt\")\n",
    "\n",
    "def get_image_dimensions(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Cannot open image: {image_path}\")\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    return width, height\n",
    "\n",
    "image_files = sorted(glob(os.path.join(SRC_DIR, \"*.*\")))\n",
    "for img_path in image_files:\n",
    "    w, h = get_image_dimensions(img_path)\n",
    "    model.predict(\n",
    "        source=img_path,\n",
    "        imgsz=(w, h),\n",
    "        conf=CONF_THRESHOLD,\n",
    "        iou=IOU_THRESHOLD,\n",
    "        project=OUT_PROJECT,\n",
    "        name=OUT_RUN_NAME,\n",
    "        exist_ok=True,\n",
    "        save=True,\n",
    "        save_txt=True,\n",
    "        verbose=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
